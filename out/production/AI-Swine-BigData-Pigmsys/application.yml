spring:
  application:
    name: pig-hadoop-system
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/pigms?useUnicode=true&characterEncoding=utf-8&useSSL=false&allowPublicKeyRetrieval=true

    username: root
    password: 

    #Spring Boot 默认是不注入这些属性值的，需要自己绑定
    #druid 数据源专有配置
    initialSize: 5
    minIdle: 5
    maxActive: 20
    maxWait: 60000
    timeBetweenEvictionRunsMillis: 60000
    minEvictableIdleTimeMillis: 300000
    validationQuery: SELECT 1 FROM DUAL
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    poolPreparedStatements: true


    #配置监控统计拦截的filters，stat:监控统计、log4j：日志记录、wall：防御sql注入
    #如果允许时报错  java.lang.ClassNotFoundException: org.apache.log4j.Priority
    #则导入 log4j 依赖即可，Maven 地址：https://mvnrepository.com/artifact/log4j/log4j
    filters: stat,wall,log4j
    maxPoolPreparedStatementPerConnectionSize: 20
    useGlobalDataSourceStat: true
    connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500

mybatis:
  type-aliases-package: com.zhu.pojo
  mapper-locations: classpath:mybatis/mapper/*.xml


# 配置分页插件的配置
pagehelper:
  helper-dialect: mysql
  reasonable: true
  support-methods-arguments: true

# Python 预测服务地址（可选，不启动 Python 服务会使用模拟数据）
python:
  service:
    url: http://localhost:5000

# Hadoop 集群配置
hadoop:
  # NameNode 地址（您的实际集群配置）
  namenode: hdfs://localhost:9000
  # YARN ResourceManager 地址
  resourcemanager: localhost:8032
  # NameNode Web UI (Hadoop 2.x 使用 50070)
  namenode-web-ui: http://192.168.100.10:9870
  # SecondaryNameNode Web UI
  secondary-namenode-web-ui: http://localhost:50090
  # HDFS 工作目录
  hdfs:
    base-path: /pig-system
    input-path: /pig-system/input
    output-path: /pig-system/output
  # MapReduce 配置
  mapreduce:
    framework: yarn
  # 用户名（HDFS 访问用户）
  user: wyb
